### Academic statement

My main interest in neuroscience is the problem of learning and memory: how neural circuits of varying degrees of complexity can store and retrieve information accurately and reliably, in spite of the formidable constraints imposed on them by biology. This is a necessary process for the scientific community to understand if we want to move beyond a simplistic model of the brain as a mapping from perceptual inputs to behavioral outputs. My goal in research, at least for the near future, is to apply my background in computer science and statistics to the study of memory, in order to develop both tools for analyzing experimental data and models of the computations that neural circuits perform in order to store and retrieve memories.

My first exposure to research at the intersection of neuroscience and machine learning was working on my undergraduate thesis at Princeton with Prof. Jonathan Pillow. My project focused on improving Baysian optimization, an existing black-box optimization method, to make it more useful for fitting statistical models to neural data. Bayesian optimization recasts the problem of optimization as one of Bayesian inference: the function being optimized is assumed to be drawn from some prior stochastic process, which, when combined with observations of the function's values at a set of chosen test points, yields a posterior distribution over possible functions, and an expected optimum. Many strategies existed for choosing test points, but none of them worked well on the types of functions we were trying to optimize, where the level of noise in each function observation is not constant, but dependent on the input value. For my thesis project, I used a result from the experimental design literature to create a new strategy for test point selection specficially tailored to these types of functions, and demonstrated its efficacy using numerical simulations. Although this project was only tangentially related to neuroscience, I learned about the field by attending our lab meetings and discussing papers, and I became familiar with many of the models and tools used for analyzing neural data.

In May of this year, I joined Prof. Cristina Savin's lab at NYU as a research assistant. Prof. Savin's research focus is computational modeling of memory, plasticity and learning, which lines up really well with my current interests. So far, I have worked primarily on using Gaussian process models (the same type of models I used for my Bayesian optimization work with Prof. Pillow) to infer tuning curves from neural recordings. While Gaussian process models have existed for a long time, algorithms that tractably fit them to large datasets have only recently been introduced, allowing us for the first time to use them to analyze many types of neural data. For the first project I worked on, starting in June, we tried to apply this approach to calcium imaging data recorded from the CA3 hippocampal region in rodents performing a spatial navigation task. Unfortunately, this data turned out to be too sparse for our tuning curve inference to work on it. This was disappointing for sure, but also gave me a lot of valuable experience working with experimental data. For the second project, which we are still working on, we are applying the same method to electrophysiological data recorded from the medial entorhinal cortex of rodents performing a different spatial navigation task. Luckily, we've been able to reuse a lot of the data analysis tools we developed for the first project on this one.

One of the things that I really like about the research being done at NYU's Center for Neural Science is the emphasis placed on biological realism, even in the more computationally-oriented labs. Prof. Savin's work on memory and learning seeks to build models of how these processes are realized on a circuit-level that are consistent with known biological facts about neurons and synapses. I've seen this theoretically principled, biologically conscious approach to neurosciece Prof. Eero Simoncelli's work on vision and Prof. Wei Ji Ma's work applying Bayesian inference to decision-making. Because of the opportunity to work with researchers like these, as well as the opportunity to engage seriously with the biology of neural systems while still advancing my knowledge of theoretical principles, I believe NYU would be an excellent place to pursue my PhD in neuroscience.
