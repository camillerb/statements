### Academic statement

My main interest in neuroscience is the relationship between neural coding and memory. How do neural circuits use efficient representations to reliably store and retrieve information, in spite of the formidable constraints imposed by biology? Understanding how the brain's internal state is encoded and persisted [this sounds a bit awk. maybe maintained?] is essential to modeling phenomena that cannot be explained as simple mappings, such as sensory inputs or behavioral outputs. My current goal in research is to apply my background in computer science and statistics to the study of neural coding and memory and develop both tools for analyzing experimental data and models of neural computations.

My first exposure to research at the intersection of neuroscience and machine learning was working on my undergraduate thesis with Prof. Jonathan Pillow [princeton is implied]. My project focused on making Bayesian optimization, a black-box optimization method, more useful for fitting statistical models to neural data *]*. Bayesian optimization recasts the problem of optimization as one of inference: the function being optimized is assumed to be drawn from a Gaussian process prior, which, when combined with observations of the function's values at a set of chosen test points, yields a posterior distribution over possible function values and an expected optimal value. Many strategies exist for choosing test points, but none of them work well on the types of functions we were trying to optimize, where the level of noise in each function observation is not constant, but dependent on the input value [maybe talk a little bit more about this kind of data, or introduce the problem of why this data is so hard to analyze a bit earlier, perhaps at the *]* is this neural data you're talking about? is it a specific sub-class of neural data? why is this data so important to understand?]. I used results from experimental design literature to create a new strategy for test point selection specifically tailored to these types of functions, and demonstrated its efficacy using numerical simulations. Although this project was only tangentially [i dont like this ... maybe say something more like outside the scope of traditional neuroscience?] related to neuroscience, [or maybe just start this sentence saying: Furthermore, I learned..] I learned about the field by attending our lab meetings and discussing papers, and I became familiar with many of the models and tools used for analyzing neural data. [Or maybe something like .. The experience of being in the lab, reading papers attending meetings etc provided an invaluable introduction to the many models and tools used for analyzing neural data as well as the field at large]. 

In May of this year, I joined Prof. Cristina Savin's lab at NYU as a research assistant. [Why were you motivated to join here lab?] Prof. Savin's research focus is computational modeling of memory, plasticity and learning. I work primarily on using Gaussian process models to infer tuning curves from neural recordings. While Gaussian process models have existed for a long time, algorithms that tractably fit them to large datasets have only recently been introduced. These algorithms allow us for the first time to analyze many types of neural data. For the first project I worked on, we tried to apply this approach to calcium imaging data recorded from the CA3 hippocampal region in rodents performing a spatial navigation task. Unfortunately, this data turned out to be too sparse for our tuning curve inference to work on it. This was disappointing for sure, but also gave me a lot of valuable experience working with experimental data[yeeesss!]. For the second project, currently in progress, we are applying the same method to electrophysiological data recorded from the medial entorhinal cortex of rodents performing a different spatial navigation task. Luckily, we've been able to reuse a lot of the data analysis tools we developed for the first project on this one. [is there anything you learned specifically from the first failure that you apply here?]

One of the aspects of the research being done at NYU's Center for Neural Science that I find unique is the emphasis placed on biological realism, even in the more computationally oriented labs. Prof. Savin's work on memory and learning seeks to build models of how these processes are realized on a circuit-level that are consistent with known biological facts about neurons and synapses. I have also seen this theoretically principled, biologically conscious approach to neuroscience in Prof. Eero Simoncelli's work on the encoding of visual information and Prof. John Rinzel's work on the neural dynamics underlying auditory perception. Because of the opportunity to work with researchers like these, as well as the opportunity to engage seriously with the biology of neural systems while still advancing my knowledge of theoretical principles, I believe NYU would be an exceptional place to pursue my PhD in neuroscience. [YESSSSSS amazing end]
